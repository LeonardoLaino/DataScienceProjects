{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui irei realizar a etapa de Feature Engineering na base de dados `bureau`.\n",
    "\n",
    "Esta etapa está dividida em kernels diferentes devido o consumo de memória para carregar e manipular as bases.\n",
    "\n",
    "Os procedimentos realizados nas outras bases podem ser encontrados nos arquivos `02_feat_eng_<nome-da-base>.ipynb`\n",
    "\n",
    "O objetivo desta etapa consiste, principalmente, em criar variáveis (`book de variáveis`). Ao criar novas variáveis com base nas variáveis existentes, é possível capturar informações adicionais que podem não estar explicitamente presentes nos dados originais.\n",
    "\n",
    "Devido o volume de dados, optei por utilizar o PySpark em conjunto com o SparkSQL para as operações a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sobre os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base `bureau` possui dados de crédito de outras instituições financeiras.\n",
    "\n",
    "Segundo os Metadados disponibilizados, essas são as informações contidas aqui:\n",
    "\n",
    "``SK_BUREAU_ID``: ID recodificado do crédito do Bureau de Crédito (codificação única para cada aplicação) - Será usado para trazer os dados da tabela `bureau balance`.\n",
    "\n",
    "``SK_ID_CURR``: ID do empréstimo em nossa amostra - um empréstimo em nossa amostra pode ter 0, 1, 2 ou mais créditos anteriores relacionados no bureau de crédito.\n",
    "\n",
    "`CREDIT_ACTIVE`: Status dos créditos reportados pelo Bureau de Crédito (CB).\n",
    "\n",
    "`CREDIT_CURRENCY`: Moeda recodificada do crédito do Bureau de Crédito.\n",
    "\n",
    "`DAYS_CREDIT`: Quantos dias antes da aplicação atual o cliente solicitou crédito ao Bureau de Crédito.\n",
    "\n",
    "`CREDIT_DAY_OVERDUE`: Número de dias em atraso no crédito do CB no momento da aplicação para o empréstimo relacionado em nossa amostra.\n",
    "\n",
    "`DAYS_CREDIT_ENDDATE`: Duração restante do crédito do CB (em dias) no momento da aplicação no Home Credit.\n",
    "\n",
    "`DAYS_ENDDATE_FACT`: Dias desde que o crédito do CB foi encerrado no momento da aplicação no Home Credit (apenas para créditos encerrados).\n",
    "\n",
    "`AMT_CREDIT_MAX_OVERDUE`: Valor máximo em atraso no crédito do Bureau de Crédito até o momento (na data de aplicação do empréstimo em nossa amostra).\n",
    "\n",
    "`CNT_CREDIT_PROLONG`: Quantas vezes o crédito do Bureau de Crédito foi prolongado.\n",
    "\n",
    "`AMT_CREDIT_SUM`: Valor atual do crédito para o crédito do Bureau de Crédito.\n",
    "\n",
    "`AMT_CREDIT_SUM_DEBT`: Dívida atual no crédito do Bureau de Crédito.\n",
    "\n",
    "`AMT_CREDIT_SUM_LIMIT`: Limite de crédito atual do cartão de crédito relatado no Bureau de Crédito.\n",
    "\n",
    "`AMT_CREDIT_SUM_OVERDUE`: Valor atual em atraso no crédito do Bureau de Crédito.\n",
    "\n",
    "`CREDIT_TYPE`: Tipo de crédito do Bureau de Crédito (Carro, dinheiro, ...).\n",
    "\n",
    "`DAYS_CREDIT_UPDATE`: Quantos dias antes da aplicação do empréstimo foi recebida a última informação sobre o crédito do Bureau de Crédito.\n",
    "\n",
    "`AMT_ANNUITY`: Anuidade do crédito do Bureau de Crédito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importando as bibliotecas que irei utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m when,\u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m, \u001b[38;5;28msum\u001b[39m, \u001b[38;5;28mround\u001b[39m, col, median, count\n\u001b[1;32m----> 6\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeatureEng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filterwarnings\n\u001b[0;32m      8\u001b[0m filterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\session.py:483\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    480\u001b[0m     session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m--> 483\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSparkSession$\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODULE$\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    484\u001b[0m     )\u001b[38;5;241m.\u001b[39mapplyModifiableSettings(session\u001b[38;5;241m.\u001b[39m_jsparkSession, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m session\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1712\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m UserHelpAutoCompletion\u001b[38;5;241m.\u001b[39mKEY:\n\u001b[0;32m   1710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[1;32m-> 1712\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFLECTION_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEND_COMMAND_PART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m proto\u001b[38;5;241m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaPackage(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, jvm_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id)\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when,min, max, sum, round, col, median, count\n",
    "spark = SparkSession.builder.appName(\"FeatureEng\").getOrCreate()\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - Previous Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670214"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_app = spark.read.csv('./DATASETS/previous_application.csv', inferSchema= True, header= True)\n",
    "prev_app.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+-----------+---------------+----------+----------------+---------------+--------------------------+-----------------------+---------------------------+----------------------+-----------------+---------------------+------------------------+----------------------+--------------------+-------------+--------------------+------------------+---------------+----------------+-------------------+--------------+-----------------+--------------------+----------------+--------------------+-----------+----------------+--------------------+------------------+--------------+-------------------------+-------------+----------------+-------------------------+\n",
      "|SK_ID_PREV|SK_ID_CURR|NAME_CONTRACT_TYPE|AMT_ANNUITY|AMT_APPLICATION|AMT_CREDIT|AMT_DOWN_PAYMENT|AMT_GOODS_PRICE|WEEKDAY_APPR_PROCESS_START|HOUR_APPR_PROCESS_START|FLAG_LAST_APPL_PER_CONTRACT|NFLAG_LAST_APPL_IN_DAY|RATE_DOWN_PAYMENT|RATE_INTEREST_PRIMARY|RATE_INTEREST_PRIVILEGED|NAME_CASH_LOAN_PURPOSE|NAME_CONTRACT_STATUS|DAYS_DECISION|   NAME_PAYMENT_TYPE|CODE_REJECT_REASON|NAME_TYPE_SUITE|NAME_CLIENT_TYPE|NAME_GOODS_CATEGORY|NAME_PORTFOLIO|NAME_PRODUCT_TYPE|        CHANNEL_TYPE|SELLERPLACE_AREA|NAME_SELLER_INDUSTRY|CNT_PAYMENT|NAME_YIELD_GROUP| PRODUCT_COMBINATION|DAYS_FIRST_DRAWING|DAYS_FIRST_DUE|DAYS_LAST_DUE_1ST_VERSION|DAYS_LAST_DUE|DAYS_TERMINATION|NFLAG_INSURED_ON_APPROVAL|\n",
      "+----------+----------+------------------+-----------+---------------+----------+----------------+---------------+--------------------------+-----------------------+---------------------------+----------------------+-----------------+---------------------+------------------------+----------------------+--------------------+-------------+--------------------+------------------+---------------+----------------+-------------------+--------------+-----------------+--------------------+----------------+--------------------+-----------+----------------+--------------------+------------------+--------------+-------------------------+-------------+----------------+-------------------------+\n",
      "|   2030495|    271877|    Consumer loans|    1730.43|        17145.0|   17145.0|             0.0|        17145.0|                  SATURDAY|                     15|                          Y|                     1|              0.0|  0.18283180324152784|      0.8673361522198731|                   XAP|            Approved|          -73|Cash through the ...|               XAP|           null|        Repeater|             Mobile|           POS|              XNA|        Country-wide|              35|        Connectivity|       12.0|          middle|POS mobile with i...|          365243.0|         -42.0|                    300.0|        -42.0|           -37.0|                      0.0|\n",
      "|   2802425|    108129|        Cash loans|  25188.615|       607500.0|  679671.0|            null|       607500.0|                  THURSDAY|                     11|                          Y|                     1|             null|                 null|                    null|                   XNA|            Approved|         -164|                 XNA|               XAP|  Unaccompanied|        Repeater|                XNA|          Cash|           x-sell|      Contact center|              -1|                 XNA|       36.0|      low_action|    Cash X-Sell: low|          365243.0|        -134.0|                    916.0|     365243.0|        365243.0|                      1.0|\n",
      "|   2523466|    122040|        Cash loans|  15060.735|       112500.0|  136444.5|            null|       112500.0|                   TUESDAY|                     11|                          Y|                     1|             null|                 null|                    null|                   XNA|            Approved|         -301|Cash through the ...|               XAP|Spouse, partner|        Repeater|                XNA|          Cash|           x-sell|Credit and cash o...|              -1|                 XNA|       12.0|            high|   Cash X-Sell: high|          365243.0|        -271.0|                     59.0|     365243.0|        365243.0|                      1.0|\n",
      "|   2819243|    176158|        Cash loans|  47041.335|       450000.0|  470790.0|            null|       450000.0|                    MONDAY|                      7|                          Y|                     1|             null|                 null|                    null|                   XNA|            Approved|         -512|Cash through the ...|               XAP|           null|        Repeater|                XNA|          Cash|           x-sell|Credit and cash o...|              -1|                 XNA|       12.0|          middle| Cash X-Sell: middle|          365243.0|        -482.0|                   -152.0|       -182.0|          -177.0|                      1.0|\n",
      "|   1784265|    202054|        Cash loans|  31924.395|       337500.0|  404055.0|            null|       337500.0|                  THURSDAY|                      9|                          Y|                     1|             null|                 null|                    null|               Repairs|             Refused|         -781|Cash through the ...|                HC|           null|        Repeater|                XNA|          Cash|          walk-in|Credit and cash o...|              -1|                 XNA|       24.0|            high|   Cash Street: high|              null|          null|                     null|         null|            null|                     null|\n",
      "+----------+----------+------------------+-----------+---------------+----------+----------------+---------------+--------------------------+-----------------------+---------------------------+----------------------+-----------------+---------------------+------------------------+----------------------+--------------------+-------------+--------------------+------------------+---------------+----------------+-------------------+--------------+-----------------+--------------------+----------------+--------------------+-----------+----------------+--------------------+------------------+--------------+-------------------------+-------------+----------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev_app.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checando a quantidade de linhas da tabela final (para validação posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670214"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_app.groupBy(\"SK_ID_PREV\").count().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Verificando o Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SK_ID_PREV: integer (nullable = true)\n",
      " |-- SK_ID_CURR: integer (nullable = true)\n",
      " |-- NAME_CONTRACT_TYPE: string (nullable = true)\n",
      " |-- AMT_ANNUITY: double (nullable = true)\n",
      " |-- AMT_APPLICATION: double (nullable = true)\n",
      " |-- AMT_CREDIT: double (nullable = true)\n",
      " |-- AMT_DOWN_PAYMENT: double (nullable = true)\n",
      " |-- AMT_GOODS_PRICE: double (nullable = true)\n",
      " |-- WEEKDAY_APPR_PROCESS_START: string (nullable = true)\n",
      " |-- HOUR_APPR_PROCESS_START: integer (nullable = true)\n",
      " |-- FLAG_LAST_APPL_PER_CONTRACT: string (nullable = true)\n",
      " |-- NFLAG_LAST_APPL_IN_DAY: integer (nullable = true)\n",
      " |-- RATE_DOWN_PAYMENT: double (nullable = true)\n",
      " |-- RATE_INTEREST_PRIMARY: double (nullable = true)\n",
      " |-- RATE_INTEREST_PRIVILEGED: double (nullable = true)\n",
      " |-- NAME_CASH_LOAN_PURPOSE: string (nullable = true)\n",
      " |-- NAME_CONTRACT_STATUS: string (nullable = true)\n",
      " |-- DAYS_DECISION: integer (nullable = true)\n",
      " |-- NAME_PAYMENT_TYPE: string (nullable = true)\n",
      " |-- CODE_REJECT_REASON: string (nullable = true)\n",
      " |-- NAME_TYPE_SUITE: string (nullable = true)\n",
      " |-- NAME_CLIENT_TYPE: string (nullable = true)\n",
      " |-- NAME_GOODS_CATEGORY: string (nullable = true)\n",
      " |-- NAME_PORTFOLIO: string (nullable = true)\n",
      " |-- NAME_PRODUCT_TYPE: string (nullable = true)\n",
      " |-- CHANNEL_TYPE: string (nullable = true)\n",
      " |-- SELLERPLACE_AREA: integer (nullable = true)\n",
      " |-- NAME_SELLER_INDUSTRY: string (nullable = true)\n",
      " |-- CNT_PAYMENT: double (nullable = true)\n",
      " |-- NAME_YIELD_GROUP: string (nullable = true)\n",
      " |-- PRODUCT_COMBINATION: string (nullable = true)\n",
      " |-- DAYS_FIRST_DRAWING: double (nullable = true)\n",
      " |-- DAYS_FIRST_DUE: double (nullable = true)\n",
      " |-- DAYS_LAST_DUE_1ST_VERSION: double (nullable = true)\n",
      " |-- DAYS_LAST_DUE: double (nullable = true)\n",
      " |-- DAYS_TERMINATION: double (nullable = true)\n",
      " |-- NFLAG_INSURED_ON_APPROVAL: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev_app.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Criação de Flags Temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670214"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma View\n",
    "prev_app.createOrReplaceTempView('prev_app')\n",
    "\n",
    "temp01 = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "        CASE\n",
    "            WHEN DAYS_DECISION >= -90 THEN 1\n",
    "        ELSE 0\n",
    "    END AS FL_U3M,\n",
    "        CASE\n",
    "            WHEN DAYS_DECISION >= -180 THEN 1\n",
    "        ELSE 0\n",
    "    END AS FL_U6M,\n",
    "        CASE\n",
    "            WHEN DAYS_DECISION >= -270 THEN 1\n",
    "        ELSE 0\n",
    "    END AS FL_U9M,\n",
    "        CASE\n",
    "            WHEN DAYS_DECISION >= -360 THEN 1\n",
    "        ELSE 0\n",
    "    END AS FL_U12M\n",
    "FROM\n",
    "    prev_app\n",
    "ORDER BY\n",
    "    `SK_ID_PREV`;\n",
    "\"\"\")\n",
    "\n",
    "temp01.createOrReplaceTempView('temp01')\n",
    "temp01.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Realizando os Joins com as Bases Tratadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Carregando a POS Cash Balance, Credit Card Balance, Instalments Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash = spark.read.parquet(\"./BASES_FEAT_ENG/POS_CASH_BALANCE_FEAT_ENG\")\n",
    "instalments = spark.read.parquet(\"./BASES_FEAT_ENG/INSTALMENTS_PAYMENTS_FEAT_ENG\")\n",
    "credit_balance = spark.read.parquet(\"./BASES_FEAT_ENG/CREDIT_CARD_BALANCE_FEAT_ENG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Realizando os Joins utilizando a **SK_ID_PREV** como chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670214"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp02 = temp01.join(pos_cash, \"SK_ID_PREV\", how = 'left').join(credit_balance, \"SK_ID_PREV\", how = 'left').join(instalments, \"SK_ID_PREV\", how = 'left')\n",
    "temp02.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp02.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Criação das Variáveis (Agrupadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtrando as colunas que não serão agregadas (Optei por remover devido limitações computacionais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_temporais = ['FL_U3M', 'FL_U6M', 'FL_U9M','FL_U12M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo as colunas de IDs\n",
    "agg_cols = [col for col in temp02.columns if \"SK_ID\" not in col]\n",
    "len(agg_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo as colunas de Flags Temporais\n",
    "for _ in flags_temporais:\n",
    "    agg_cols.remove(_)\n",
    "len(agg_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando as colunas categóricas (não irão entrar nas agregações)\n",
    "catcols = [cat_col[0] for cat_col in temp01.dtypes if cat_col[1] == 'string']\n",
    "len(catcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in catcols:\n",
    "#     agg_cols.remove(_)\n",
    "# len(agg_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in catcols:\n",
    "    agg_cols.remove(_)\n",
    "len(agg_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Usando Apenas Flags Temporais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Flag Temporal: U3M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = []\n",
    "\n",
    "temp_flag = flags_temporais[0]\n",
    "\n",
    "for agg_col in agg_cols:\n",
    "  if 'DPD' in agg_col or 'DAY' in agg_col:\n",
    "    new_cols.append(round(max(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"QT_MAX_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "    new_cols.append(round(min(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"QT_MIN_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "  else:\n",
    "    new_cols.append(round(sum(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"VL_TOT_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "    new_cols.append(round(median(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"VL_MED_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "    new_cols.append(round(max(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"VL_MAX_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "    new_cols.append(round(min(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"VL_MIN_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "\n",
    "\n",
    "new_cols = tuple(new_cols)\n",
    "\n",
    "temp03 = temp02.groupBy(\"SK_ID_CURR\").agg(*new_cols).orderBy(\"SK_ID_CURR\")\n",
    "\n",
    "temp03.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Spark\\python\\pyspark\\errors\\exceptions\\captured.py\", line 169, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"C:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <exception str() failed>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "org does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(10061, 'Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente', None, 10061, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m temp03 \u001b[38;5;241m=\u001b[39m temp03\u001b[38;5;241m.\u001b[39mrepartition(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtemp03\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./BASES_FEAT_ENG/PREV_APP_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\readwriter.py:1656\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[1;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[1;32m-> 1656\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\errors\\exceptions\\captured.py:171\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 171\u001b[0m     converted \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\errors\\exceptions\\captured.py:163\u001b[0m, in \u001b[0;36mconvert_exception\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m    157\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  An exception was thrown from the Python worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the stack trace below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c\u001b[38;5;241m.\u001b[39mgetMessage()\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PythonException(msg, stacktrace)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnknownException\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstackTrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacktrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\errors\\exceptions\\captured.py:64\u001b[0m, in \u001b[0;36mCapturedException.__init__\u001b[1;34m(self, desc, stackTrace, cause, origin)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstackTrace \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     stackTrace\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stackTrace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (SparkContext\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mUtils\u001b[38;5;241m.\u001b[39mexceptionString(origin))\n\u001b[0;32m     63\u001b[0m )\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin\u001b[38;5;241m.\u001b[39mgetCause() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m convert_exception(origin\u001b[38;5;241m.\u001b[39mgetCause())\n",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\errors\\exceptions\\captured.py:147\u001b[0m, in \u001b[0;36mconvert_exception\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkUpgradeException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m    146\u001b[0m c: Py4JJavaError \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mgetCause()\n\u001b[1;32m--> 147\u001b[0m stacktrace: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mjvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morg\u001b[49m\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mUtils\u001b[38;5;241m.\u001b[39mexceptionString(e)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    149\u001b[0m     is_instance_of(gw, c, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.api.python.PythonException\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# To make sure this only catches Python UDFs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    156\u001b[0m ):\n\u001b[0;32m    157\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  An exception was thrown from the Python worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the stack trace below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c\u001b[38;5;241m.\u001b[39mgetMessage()\n\u001b[0;32m    160\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1725\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1722\u001b[0m _, error_message \u001b[38;5;241m=\u001b[39m get_error_message(answer)\n\u001b[0;32m   1723\u001b[0m message \u001b[38;5;241m=\u001b[39m compute_exception_message(\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not exist in the JVM\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name), error_message)\n\u001b[1;32m-> 1725\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(message)\n",
      "\u001b[1;31mPy4JError\u001b[0m: org does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "temp03 = temp03.repartition(1)\n",
    "temp03.write.parquet(\"./BASES_FEAT_ENG/PREV_APP_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberando Memória\n",
    "temp03 = None\n",
    "del(temp03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Flag Temporal: U6M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "\n",
    "temp_flag = flags_temporais[1]\n",
    "\n",
    "for agg_col in agg_cols:\n",
    "  if 'DPD' in agg_col or 'DAY' in agg_col:\n",
    "    new_cols.append(round(max(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"QT_MAX_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "    new_cols.append(round(min(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"QT_MIN_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "  else:\n",
    "    new_cols.append(round(sum(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"VL_TOT_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "    new_cols.append(round(median(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"VL_MED_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "    new_cols.append(round(max(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"VL_MAX_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "    new_cols.append(round(min(when(col(temp_flag) == 1, col(agg_col))), 2).alias(f\"VL_MIN_{agg_col.upper()}_{temp_flag.upper()}_PREVIOUS_APPLICATION\"))\n",
    "\n",
    "\n",
    "new_cols = tuple(new_cols)\n",
    "\n",
    "temp04 = temp02.groupBy(\"SK_ID_CURR\").agg(*new_cols).orderBy(\"SK_ID_CURR\")\n",
    "\n",
    "temp04.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp04 = temp04.repartition(1)\n",
    "temp04.write.mode(\"overwrite\").option(\"compression\", \"gzip\").parquet(\"./BASES_FEAT_ENG/PREV_APP_2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
